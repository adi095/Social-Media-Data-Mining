{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed73642-c65b-42b7-8eb2-600a79b3a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_reviews(path):\n",
    "    texts, labels = [], []\n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        folder = os.path.join(path, sentiment)\n",
    "        for file in os.listdir(folder):\n",
    "            with open(os.path.join(folder, file), 'r', encoding='utf-8') as f:\n",
    "                texts.append(f.read())\n",
    "                labels.append(1 if sentiment == 'pos' else 0)\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = load_reviews('./train')\n",
    "test_texts, test_labels = load_reviews('./test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8e1d98-fe63-46e8-a0f3-8ec8700955cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Bag-of-Words (BoW)\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(train_texts)\n",
    "X_test_bow = bow_vectorizer.transform(test_texts)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55e0c264-ae5b-4026-95df-dab1dc363940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "    }\n",
    "results = {}\n",
    "\n",
    "# --- Naive Bayes on Bag-of-Words ---\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(X_train_bow, train_labels)\n",
    "y_pred_nb_bow = nb_bow.predict(X_test_bow)\n",
    "results['NaiveBayes_BoW'] = evaluate(test_labels, y_pred_nb_bow)\n",
    "\n",
    "# --- Logistic Regression on Bag-of-Words ---\n",
    "lr_bow = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
    "lr_bow.fit(X_train_bow, train_labels)\n",
    "y_pred_lr_bow = lr_bow.predict(X_test_bow)\n",
    "results['LogReg_BoW'] = evaluate(test_labels, y_pred_lr_bow)\n",
    "\n",
    "# --- Naive Bayes on TF-IDF ---\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, train_labels)\n",
    "y_pred_nb_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "results['NaiveBayes_TFIDF'] = evaluate(test_labels, y_pred_nb_tfidf)\n",
    "\n",
    "# --- Logistic Regression on TF-IDF ---\n",
    "lr_tfidf = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
    "lr_tfidf.fit(X_train_tfidf, train_labels)\n",
    "y_pred_lr_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "results['LogReg_TFIDF'] = evaluate(test_labels, y_pred_lr_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65595a40-0131-4537-a721-3c4a82a5e7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy  Precision   Recall  F1 Score\n",
      "NaiveBayes_BoW     0.81356   0.860546  0.74840  0.800565\n",
      "LogReg_BoW         0.86672   0.872622  0.85880  0.865656\n",
      "NaiveBayes_TFIDF   0.82956   0.874126  0.77000  0.818766\n",
      "LogReg_TFIDF       0.88316   0.884113  0.88192  0.883015\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(df_results)\n",
    "\n",
    "df_results.to_csv(\"results.txt\", sep=\"\\t\", float_format=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e01298c7-be8e-4ddf-888b-2ea8f7ecadaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW vs TF-IDF comparison:\n",
      "                  Accuracy  Precision   Recall  F1 Score\n",
      "NaiveBayes_BoW     0.81356   0.860546  0.74840  0.800565\n",
      "NaiveBayes_TFIDF   0.82956   0.874126  0.77000  0.818766\n",
      "LogReg_BoW         0.86672   0.872622  0.85880  0.865656\n",
      "LogReg_TFIDF       0.88316   0.884113  0.88192  0.883015\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"BoW vs TF-IDF comparison:\")\n",
    "print(df_results.loc[[\"NaiveBayes_BoW\", \"NaiveBayes_TFIDF\", \"LogReg_BoW\", \"LogReg_TFIDF\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "874d5016-bc13-4dca-8135-65b8adf104d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW with stop word removal\n",
    "bow_sw = CountVectorizer(stop_words='english')\n",
    "X_train_bow_sw = bow_sw.fit_transform(train_texts)\n",
    "X_test_bow_sw = bow_sw.transform(test_texts)\n",
    "\n",
    "# TF-IDF with stop word removal\n",
    "tfidf_sw = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf_sw = tfidf_sw.fit_transform(train_texts)\n",
    "X_test_tfidf_sw = tfidf_sw.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa7743c-c75c-4cd0-b15d-03c307e2f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on BoW with stop words removed\n",
    "nb_bow_sw = MultinomialNB().fit(X_train_bow_sw, train_labels)\n",
    "results['NaiveBayes_BoW_Stopwords'] = evaluate(test_labels, nb_bow_sw.predict(X_test_bow_sw))\n",
    "\n",
    "# Logistic Regression on BoW with stop words removed\n",
    "lr_bow_sw = LogisticRegression(penalty='l2', solver='liblinear').fit(X_train_bow_sw, train_labels)\n",
    "results['LogReg_BoW_Stopwords'] = evaluate(test_labels, lr_bow_sw.predict(X_test_bow_sw))\n",
    "\n",
    "# Naive Bayes on TF-IDF with stop words removed\n",
    "nb_tfidf_sw = MultinomialNB().fit(X_train_tfidf_sw, train_labels)\n",
    "results['NaiveBayes_TFIDF_Stopwords'] = evaluate(test_labels, nb_tfidf_sw.predict(X_test_tfidf_sw))\n",
    "\n",
    "# Logistic Regression on TF-IDF with stop words removed\n",
    "lr_tfidf_sw = LogisticRegression(penalty='l2', solver='liblinear').fit(X_train_tfidf_sw, train_labels)\n",
    "results['LogReg_TFIDF_Stopwords'] = evaluate(test_labels, lr_tfidf_sw.predict(X_test_tfidf_sw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bc8085f-eb2f-4001-a201-2cb661a79b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 (already done above)\n",
    "# L1\n",
    "lr_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lr_l1.fit(X_train_tfidf_sw, train_labels)\n",
    "results['LogReg_TFIDF_Stopwords_L1'] = evaluate(test_labels, lr_l1.predict(X_test_tfidf_sw))\n",
    "\n",
    "# No regularization with more iterations\n",
    "lr_none = LogisticRegression(penalty='none', solver='saga', max_iter=5000)\n",
    "lr_none.fit(X_train_tfidf_sw, train_labels)\n",
    "results['LogReg_TFIDF_Stopwords_None'] = evaluate(test_labels, lr_none.predict(X_test_tfidf_sw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98569efc-070d-4585-9893-e36aef8339e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Accuracy  Precision   Recall  F1 Score\n",
      "NaiveBayes_BoW                0.81356   0.860546  0.74840  0.800565\n",
      "LogReg_BoW                    0.86672   0.872622  0.85880  0.865656\n",
      "NaiveBayes_TFIDF              0.82956   0.874126  0.77000  0.818766\n",
      "LogReg_TFIDF                  0.88316   0.884113  0.88192  0.883015\n",
      "NaiveBayes_BoW_Stopwords      0.81968   0.863207  0.75976  0.808187\n",
      "LogReg_BoW_Stopwords          0.85908   0.865602  0.85016  0.857812\n",
      "NaiveBayes_TFIDF_Stopwords    0.82992   0.865279  0.78152  0.821269\n",
      "LogReg_TFIDF_Stopwords        0.87900   0.877881  0.88048  0.879179\n",
      "LogReg_TFIDF_Stopwords_L1     0.87336   0.863417  0.88704  0.875069\n",
      "LogReg_TFIDF_Stopwords_None   0.84768   0.859530  0.83120  0.845128\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame(results).T\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(df_all)\n",
    "# Optional: Save to results.txt\n",
    "df_all.to_csv(\"results.txt\", sep=\"\\t\", float_format=\"%.4f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f8a90-1902-4794-8d3c-40bee11ab2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
